<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>The Claw by carolkng</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">The Claw</h1>
      <h2 class="project-tagline">A fully autonomous Uber-bot for stuffed animal transportation.</h2>
      <a href="https://github.com/carolkng/the-claw" class="btn">View on GitHub</a>
      <a href="https://github.com/carolkng/the-claw/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/carolkng/the-claw/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Table of Contents</h2>

<ol>
<li><a href="#1-introduction">Introduction</a></li>
<li><a href="#2-mechanical-design">Mechanical Design</a></li>
<li>
<a href="#3-electrical-design">Electrical Design</a>

<ol>
<li><a href="#31-tapefinding">Tapefinding</a></li>
<li>
<a href="#32-infrared-sensing">Infrared sensing</a><br>
</li>
</ol>
</li>
<li>
<a href="#4-software">Software</a>

<ol>
<li><a href="#41-navigation">Navigation</a></li>
<li><a href="#42-intersection-handling">Intersection handling</a></li>
<li><a href="#43-passenger-pickup">Passenger pickup</a></li>
<li><a href="#44-tape-following">Tape following</a></li>
<li><a href="#45-collision-detection">Collision detection</a></li>
</ol>
</li>
<li><a href="#5-performance">Performance</a></li>
</ol>

<h2>
<a id="1-introduction" class="anchor" href="#1-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1. Introduction</h2>

<p><img src="artview.jpg" alt="The robot, the myth, the legend"></p>

<p>The Claw is a robot that can navigate a city whose roads are marked with black electrical tape on a white surface using 4 QRD 1114 reflectivity sensors, detect stuffed animal passengers with QSD 1124 infrared sensors, and pick them up with a large claw. The robot receives instructions from a TINAH board running mostly Arduino code. It was created and completed in the summer of second year for the ENPH 253: Introduction to Instrument Design course/competition at UBC by Tara Akhound-Sadegh, <a href="https://carolkng.github.io">Carol Ng</a>, Jamie O'Conniff, and Dylan Whitney.</p>

<h2>
<a id="2-mechanical-design" class="anchor" href="#2-mechanical-design" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2. Mechanical design</h2>

<p>Jamie and Dylan were responsible for the majority of the robot's mechanical design. All parts were designed in Solidworks and fabricated (in order of most used) with a combination of a waterjet cutter, machine shop/hand tools, 3D printers, and a laser cutter.</p>

<p><img src="claw.jpg" alt="Initial claw design"></p>

<p>Our initial design concept featured storage for passengers holding up to 3 animals (with on in the claw), a fully articulated arm with 2 degrees of freedom on a rotating platform, and a bulk ejection system for quick dropoff of all passengers at the destination area. In order to maximize passenger storage and freedom of arm movement, the robot was to be around 14" tall with a 11" by 11" base, not including the 0.5" thick bumper on all sides to detect collisions with other robots. For the drivetrain, we opted to use two electric motors with one small gear reduction to keep the motor running at its most efficient RPM while keeping our robot moving at the desired target speed. The gears and wheels were both cut from clear polycarbonate on the waterjet cutter.</p>

<p><img src="claw2.jpg" alt="Final arm and claw">
The final robot features a similarly dimensioned arm which moves with one degree of freedom and three easily accessible vertical shelves for the TINAH board and all associated circuitry, which drastically reduces debugging and startup time. To reduce the likelihood of a collision with the sidewalk when performing U-turns, the shape of the chassis is much more rounded and compact, compared to the original. Since the original bumper design would only fit on straight edges, we opted to replace the protruding bumper with a skirt made of a thin continuous sheet of aluminum.</p>

<p>As there was not enough time to fully dimension every part in Solidworks before fabrication, our approach was to get files ready for the waterjet cutter or laser cutter as quickly as possible, then assemble parts using hand tools and non-permanent fasteners in order to see what works as quickly as possible. The major drawback of this approach was that the prototypes would not look nearly as aesthetically pleasing, and a part's holes or bends would not align as well as a completely CADed part would have.</p>

<h2>
<a id="3-electrical-design" class="anchor" href="#3-electrical-design" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3. Electrical design</h2>

<p>Tara and Carol were responsible for the construction, planning, and testing of all electronic components. Most circuit designs such as Scott's H-bridge can be found on the <a href="http://projectlab.engphys.ubc.ca">Engineering Physics Project Lab</a> site, specifically on the ENPH 253 lab pages. </p>

<h3>
<a id="31-tapefinding" class="anchor" href="#31-tapefinding" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.1. Tapefinding</h3>

<p><img src="QRD.jpg" alt="Tapefinding comparator circuit"></p>

<p>For tape following and intersection detection, we chose a system of 4 QRD 1114 sensors connected to a comparator circuit to set a threshold for HI/LO output depending on whether the robot sees tape. A testing system consisting of 4 LEDs was used to improve visual feedback when adjusting the thresholds of each QRD sensor and decrease setup time. Intersection detection was critical to our robot's ability to navigate the map and helped make sure that we didn't fall off the surface when we reached a sharp corner (more in <a href="#software">Software</a>). Although we ended up soldering one potentiometer for each sensor, it turned out that the sensors were similar enough that the tuning could have been accomplished using one potentiometer.</p>

<h3>
<a id="32-infrared-sensing" class="anchor" href="#32-infrared-sensing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.2 Infrared sensing</h3>

<p><img src="QSD.jpg" alt="Infrared sensor circuit"></p>

<p>To detect passengers both at intersections and on the sidewalk, we soldered a total of 5 infrared sensor circuits: 3 for long range infrared sensing at intersections to determine which path was more likely to contain a passenger, and 2 on either side of the robot to see if a passenger is ready to be picked up. The circuits were made of 5 key components: a DC block, a 100x amplifier, a 1kHz bandpass filter, another amplifier with tunable amplification, and a peak detector.</p>

<h2>
<a id="4-software" class="anchor" href="#4-software" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4 Software</h2>

<p>Software was jointly written by Tara and Carol using Arduino. Some PID control algorithms were reused from previous ENPH 253 labs, but other methods were written completely from scratch. You can download the Arduino project we used for the competition right <a href="https://github.com/letsmakearobot/software/archive/master.zip">here</a>. (The whole, single file source code will be released soon, I promise.)</p>

<h3>
<a id="41-navigation" class="anchor" href="#41-navigation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4.1 Navigation</h3>

<p>The robot's copy of the city's map is very similar to the adjacency matrix of a bidirectional graph, with a few key differences:</p>

<ul>
<li>The edge that the robot is travelling along is defined by two nodes:

<ul>
<li>the node that the robot is travelling <em>from</em>, represented by the row index</li>
<li>the node that the robot is travelling <em>to</em>, represented by the column index</li>
</ul>
</li>
<li>All nonzero entries are replaced by a size 3 array representing the possible nodes the robot could travel to by turning left, right, or going straight ahead at the end of the edge (when an intersection is detected) </li>
</ul>

<p>By hard coding a copy of the city's map as a lookup table in the robot's software, we were able to implement advanced intersection handling methods and minimize the time needed to return a stuffed animal passenger to the destination. Since the graph is fairly sparse (138/1200 entries are nonzero), we briefly considered using a compression of some sort to avoid reaching the memory limits on the TINAH, but decided against it in favor of decreasing the average computation time per loop.</p>

<h3>
<a id="42-intersection-handling" class="anchor" href="#42-intersection-handling" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4.2 Intersection handling</h3>

<p>Intersection detection is handled by the two outer tape sensors. When the robot senses that it's at an intersection, it reads its front, long range IR sensors to find the direction (ie. left, right, or straight ahead) of the strongest IR signal, or the highest probability of having a passenger. Because we use the IR sensor data in conjunction with the stored location and map data, we avoid the possibility of camera flashes/autofocuses triggering false positives.</p>

<h3>
<a id="43-passenger-pickup" class="anchor" href="#43-passenger-pickup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4.3 Passenger pickup</h3>

<p><img src="lift.gif" alt="Jack, I'm flying!"></p>

<p>Passenger pickup was taken care of with modular methods for controlling the arm, in addition to experimentally determined positions for pickup and dropoff. </p>

<p>Due to space constrictions, our robot was optimized for pickup on the left side of the sidewalk, so if a passenger was detected on the right, the robot would reverse itself and re-initiate the more advanced position algorithm before attempting to pick it up.</p>

<h3>
<a id="44-tape-following" class="anchor" href="#44-tape-following" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4.4 Tape following</h3>

<p><img src="spin.gif" alt="Oh, the early days."></p>

<p>Tape following was accomplished using the PID control algorithms from a previous ENPH 253 lab, with our motors being powered at about 50% PWM at cruising speed. Based on the output of the two tapefinding sensors, the robot senses its position on the tape, and corrects its position by adjusting the speed of the two drive wheels independently.</p>

<h3>
<a id="45-collision-detection" class="anchor" href="#45-collision-detection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4.5 Collision detection</h3>

<p>For our robot to qualify for the competition, we were required to install a bumper and collision detection system that would respond to a collision within 2 seconds. Using digital output pins on the TINAH, we were able to detect collisions on all sides except for the back of the robot, and turn on a dime immediately to avoid further altercations with the obstacle/rival robot. In order to maintain knowledge of our location on the map, we would reverse our previous/next nodes and continue to look for passengers or find an alternative route to the dropoff point.</p>

<h2>
<a id="5-performance" class="anchor" href="#5-performance" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>5 Performance</h2>

<p><img src="comp.gif" alt="Short video of competition run!"></p>

<p>In a controlled testing circuit, the Claw was able to stop accurately for passengers almost 100% of the time, pick up the passengers some of the time (sometimes the actual claw would push them out), and reliably navigate the course without getting lost, even when handling collisions. However, on the competition surface, our robot suffered from IR blindness due to loose female headers that connected our IR circuit to our power distribution circuit, causing it to drive right by some passengers, and run in circles around one of the city blocks, since the floating inputs of the IR sensors were pulled up internally by the TINAH. All in all, the whole month-long ordeal was a great learning experience.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/carolkng/the-claw">The Claw</a> is maintained by <a href="https://github.com/carolkng">carolkng</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
